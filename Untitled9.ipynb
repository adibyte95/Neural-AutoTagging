{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural AutoTagging\n",
    "\n",
    "author :Aditya Singh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utility import *\n",
    "from inception_blocks_v2 import *\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FaceNet model takes a lot of data and a long time to train. So following common practice in applied deep learning settings, let's just load weights that someone else has already trained. The network architecture follows the Inception model from Szegedy et al..\n",
    "\n",
    "The key things you need to know are:\n",
    "\n",
    "This network uses 96x96 dimensional RGB images as its input. Specifically, inputs a face image (or batch of  mm  face images) as a tensor of shape  (m,nC,nH,nW)=(m,3,96,96)(m,nC,nH,nW)=(m,3,96,96) \n",
    "It outputs a matrix of shape  (m,128)(m,128)  that encodes each input face image into a 128-dimensional vector\n",
    "Run the cell below to create the model for face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facial recognization model\n",
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "# printing the total no of parameters \n",
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will supply the images of the person whom you want to tag in photos.... our facial recognization model will output an 128 dimensional vector which is the encoding of the face... we will then go to each an every photograph and crop out the face part of each and every person in the image... if we can find a match between these faces and those stored in our database then we will tag those person in the image other wise we will leave the person as it is in the photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function resizes images to so that it can be used as an input to the model\n",
    "def resize_img(image):\n",
    "    image = cv2.resize(image, (96,96))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the database\n",
    "def init_database():\n",
    "    my_file = Path(\"database/user.pickle\")\n",
    "    if my_file.is_file():\n",
    "        # file exists\n",
    "        try:\n",
    "            pickle_in = open(\"database/user.pickle\",\"rb\")\n",
    "            user_db = pickle.load(pickle_in)\n",
    "            pickle_in.close()\n",
    "        except EOFError:\n",
    "            user_db = {}\n",
    "    else:\n",
    "        #file does not exists\n",
    "        # make a file and load it\n",
    "        user_db = {}\n",
    "    return user_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a user to the data base by taking snapshot from the webcam\n",
    "def add_new_user_webcam(user_db):\n",
    "    # taking name as input \n",
    "    name = input('enter the name of the user \\n')\n",
    "    #initializing the haar cascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    \n",
    "    while(True):\n",
    "        ret,img= cap.read()\n",
    "        if ret == 0:\n",
    "            print('problem in reading face ')\n",
    "            return \n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_gray = resize_img(roi_gray)\n",
    "            cv2.imwrite('images/user.'+str(name) +'.jpg',roi_gray)\n",
    "            cv2.imshow('face',img)\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    #extracting the features from the image\n",
    "    encoding = img_to_encoding(\"images/user.\" + str(name)+'.jpg', FRmodel)\n",
    "    user_db[name] = encoding\n",
    "    #saving the database\n",
    "    pickle_out = open(\"database/user.pickle\",\"wb\")\n",
    "    pickle.dump(user_db, pickle_out)\n",
    "    pickle_out.close()\n",
    "    print('user added to the database sucessfully from the webcam.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this funcion adds a new user to the database from the disk\n",
    "def add_new_user_disk(user_db):\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    for filename in os.listdir(\"upload_pic_disk\"):\n",
    "        name = filename.split(\".\")[0]\n",
    "        img_name = 'upload_pic_disk/' + str(name)+\".jpg\"\n",
    "        img = cv2.imread(img_name)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_gray = resize_img(roi_gray)\n",
    "            cv2.imwrite('images/user.'+str(name) +'.jpg',roi_gray)\n",
    "        #extracting the features from the image\n",
    "        encoding = img_to_encoding(\"images/user.\" + str(name)+'.jpg', FRmodel)    \n",
    "        user_db[name] = encoding\n",
    "        #saving the database\n",
    "        pickle_out = open(\"database/user.pickle\",\"wb\")\n",
    "        pickle.dump(user_db, pickle_out)\n",
    "        pickle_out.close()\n",
    "    print('user added to the database sucessfully from the disk.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function deletes user from the images folder and cleares the database \n",
    "def delete_user():\n",
    "    #deletes the images from the picture folder\n",
    "    filelist = [ f for f in os.listdir(\"images\") if f.endswith(\".jpg\") ]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(\"images\", f))\n",
    "    #deletes the pickle file from the database folder\n",
    "    filelist = [ f for f in os.listdir(\"database\") if f.endswith(\".pickle\") ]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(\"database\", f))\n",
    "    # clearing the user data base from the current program memory\n",
    "    user_db = {}\n",
    "    print('all the user data deleted from the data base')\n",
    "    return user_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function calculates the minimum distance between two persons and judges whose pic it is \n",
    "\n",
    "def cal_distance(encoding, user_db):\n",
    "    min_dis = 100\n",
    "    name = \"\"\n",
    "    for key in user_db.keys():\n",
    "        dist = np.linalg.norm(encoding -user_db[key] )\n",
    "        if dist < min_dis:\n",
    "            min_dis = dist\n",
    "            name = key\n",
    "    if min_dis > 0.7:\n",
    "        name= \"none\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes every picture in the picture folder and will try to tag the persons in the photograph\n",
    "def tag_pictures():\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    counter = 0\n",
    "    factor = 2\n",
    "    for filename in os.listdir(\"pictures\"):\n",
    "        img = cv2.imread(os.path.join(\"pictures\",filename))\n",
    "        #reshaping the image to match the input to the model\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "        counter = counter +1\n",
    "        print('image no : ', counter )\n",
    "        face  = 1\n",
    "        for (x,y,w,h) in faces:\n",
    "            \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            original_height, original_width = roi_gray.shape[:2]\n",
    "            resized_image = cv2.resize(roi_gray, (int(original_height*factor), int(original_width*factor)), interpolation=cv2.INTER_CUBIC )\n",
    "            roi_gray =cv2.resize(resized_image, (96,96))\n",
    "            \n",
    "            file_name = str(face) +'.jpg'\n",
    "            face = face +1 \n",
    "            cv2.imwrite(file_name, roi_gray)\n",
    "            #calculating the encoding for the images\n",
    "            encoding = img_to_encoding(file_name, FRmodel)\n",
    "            name = cal_distance(encoding , user_db)\n",
    "            cv2.putText(img,str(name),(x,y+h), font,2,(255,255,255),2)\n",
    "            file_name = 'tagged_photos/' + str(filename)\n",
    "            cv2.imwrite(file_name, img)\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the database using the custom function created above\n",
    "user_db = init_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter 1 to take photo from camera \n",
      "enter 2 to load the image from the disk. photo of the person must be present in the folder upload_pic_disk\n",
      "enter your choice :  2\n",
      "user added to the database sucessfully from the disk.....\n"
     ]
    }
   ],
   "source": [
    "# add a new user to the data base\n",
    "print(\"enter 1 to take photo from camera \")\n",
    "print(\"enter 2 to load the image from the disk. photo of the person must be present in the folder upload_pic_disk\")\n",
    "choice = input(\"enter your choice :  \")\n",
    "\n",
    "# converting str choice into integer\n",
    "choice = int(choice)\n",
    "if choice == 1:\n",
    "    add_new_user_webcam(user_db)\n",
    "elif choice == 2:\n",
    "    add_new_user_disk(user_db)\n",
    "else:\n",
    "    print('you have entered a wrong choice... read the instructions properly... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image no :  1\n",
      "image no :  2\n",
      "image no :  3\n",
      "image no :  4\n",
      "image no :  5\n",
      "image no :  6\n",
      "image no :  7\n",
      "image no :  8\n"
     ]
    }
   ],
   "source": [
    "tag_pictures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the user data deleted from the data base\n"
     ]
    }
   ],
   "source": [
    "## finally deleting all the user database from the disk\n",
    "user_db = delete_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
