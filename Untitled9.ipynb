{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural AutoTagging\n",
    "\n",
    "author :Aditya Singh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utility import *\n",
    "from inception_blocks_v2 import *\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FaceNet model takes a lot of data and a long time to train. So following common practice in applied deep learning settings, let's just load weights that someone else has already trained. The network architecture follows the Inception model from Szegedy et al..\n",
    "\n",
    "The key things you need to know are:\n",
    "\n",
    "This network uses 96x96 dimensional RGB images as its input. Specifically, inputs a face image (or batch of  mm  face images) as a tensor of shape  (m,nC,nH,nW)=(m,3,96,96)(m,nC,nH,nW)=(m,3,96,96) \n",
    "It outputs a matrix of shape  (m,128)(m,128)  that encodes each input face image into a 128-dimensional vector\n",
    "Run the cell below to create the model for face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facial recognization model\n",
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "# printing the total no of parameters \n",
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will supply the images of the person whom you want to tag in photos.... our facial recognization model will output an 128 dimensional vector which is the encoding of the face... we will then go to each an every photograph and crop out the face part of each and every person in the image... if we can find a match between these faces and those stored in our database then we will tag those person in the image other wise we will leave the person as it is in the photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function resizes images to so that it can be used as an input to the model\n",
    "def resize_img(image):\n",
    "    image = cv2.resize(image, (96,96))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the database\n",
    "def init_database():\n",
    "    my_file = Path(\"database/user.pickle\")\n",
    "    if my_file.is_file():\n",
    "        # file exists\n",
    "        try:\n",
    "            pickle_in = open(\"database/user.pickle\",\"rb\")\n",
    "            user_db = pickle.load(pickle_in)\n",
    "            pickle_in.close()\n",
    "        except EOFError:\n",
    "            user_db = {}\n",
    "    else:\n",
    "        #file does not exists\n",
    "        # make a file and load it\n",
    "        user_db = {}\n",
    "    return user_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a user to the data base\n",
    "def add_new_user(user_db):\n",
    "    # taking name as input \n",
    "    name = input('enter the name of the user \\n')\n",
    "    #initializing the haar cascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    \n",
    "    counter  = 0\n",
    "    while(True):\n",
    "        ret,img= cap.read()\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "        cv2.imshow('face',img)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_gray = resize_img(roi_gray)\n",
    "            cv2.imwrite('images/user.'+str(name) +'.jpg',roi_gray)\n",
    "            counter = counter +1\n",
    "        cv2.imshow('face',img)\n",
    "        cv2.waitKey(500)\n",
    "        counter = counter + 1\n",
    "        if counter >10:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    #extracting the features from the image\n",
    "    encoding = img_to_encoding(\"images/user.\" + str(name)+'.jpg', FRmodel)\n",
    "    user_db[name] = encoding\n",
    "    #saving the database\n",
    "    pickle_out = open(\"database/user.pickle\",\"wb\")\n",
    "    pickle.dump(user_db, pickle_out)\n",
    "    pickle_out.close()\n",
    "    print('user added to the database sucessfully.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function deletes user from the images folder and cleares the database \n",
    "def delete_user():\n",
    "    #deletes the images from the picture folder\n",
    "    filelist = [ f for f in os.listdir(\"images\") if f.endswith(\".jpg\") ]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(\"images\", f))\n",
    "    #deletes the pickle file from the database folder\n",
    "    filelist = [ f for f in os.listdir(\"database\") if f.endswith(\".pickle\") ]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(\"database\", f))\n",
    "    print('all the user data deleted from the data base')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the user data deleted from the data base\n"
     ]
    }
   ],
   "source": [
    "delete_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_db = init_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the name of the user \n",
      "aditya\n",
      "user added to the database sucessfully.....\n"
     ]
    }
   ],
   "source": [
    "add_new_user(user_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_distance(encoding, user_db):\n",
    "    for key in user_db.keys():\n",
    "        dist = np.linalg.norm(encoding -user_db[key] )\n",
    "        if dist < 0.7:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes every picture in the picture folder and will try to tag the persons in the photograph\n",
    "def tag_pictures():\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    counter = 0\n",
    "    factor = 2\n",
    "    for filename in os.listdir(\"pictures\"):\n",
    "        img = cv2.imread(os.path.join(\"pictures\",filename))\n",
    "        #reshaping the image to match the input to the model\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "        counter = counter +1\n",
    "        print('image no : ', counter )\n",
    "        face_no = 1\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            original_height, original_width = roi_gray.shape[:2]\n",
    "            resized_image = cv2.resize(roi_gray, (int(original_height*factor), int(original_width*factor)), interpolation=cv2.INTER_CUBIC )\n",
    "            roi_gray =cv2.resize(resized_image, (96,96))\n",
    "            cv2.imwrite('image.jpg', roi_gray)\n",
    "            #calculating the encoding for the images\n",
    "            encoding = img_to_encoding(\"image.jpg\", FRmodel)\n",
    "            name = cal_distance(encoding , user_db)\n",
    "            cv2.putText(img,str(name),(x,y+h), font,2,(255,255,255),2)\n",
    "            cv2.imwrite('DETECT.jpg', img)\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image no :  1\n"
     ]
    }
   ],
   "source": [
    "tag_pictures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
