{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural AutoTagging\n",
    "\n",
    "author :Aditya Singh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utility import *\n",
    "from inception_blocks_v2 import *\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FaceNet model takes a lot of data and a long time to train. So following common practice in applied deep learning settings, let's just load weights that someone else has already trained. The network architecture follows the Inception model from Szegedy et al..\n",
    "\n",
    "The key things you need to know are:\n",
    "\n",
    "This network uses 96x96 dimensional RGB images as its input. Specifically, inputs a face image (or batch of  mm  face images) as a tensor of shape  (m,nC,nH,nW)=(m,3,96,96)(m,nC,nH,nW)=(m,3,96,96) \n",
    "It outputs a matrix of shape  (m,128)(m,128)  that encodes each input face image into a 128-dimensional vector\n",
    "Run the cell below to create the model for face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facial recognization model\n",
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "# printing the total no of parameters \n",
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will supply the images of the person whom you want to tag in photos.... our facial recognization model will output an 128 dimensional vector which is the encoding of the face... we will then go to each an every photograph and crop out the face part of each and every person in the image... if we can find a match between these faces and those stored in our database then we will tag those person in the image other wise we will leave the person as it is in the photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function resizes images to so that it can be used as an input to the model\n",
    "def resize_img(image):\n",
    "    image = cv2.resize(image, (96,96))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the database\n",
    "def init_database():\n",
    "    my_file = Path(\"database/user.pickle\")\n",
    "    if my_file.is_file():\n",
    "        # file exists\n",
    "        pickle_in = open(\"database/user.pickle\",\"rb\")\n",
    "        user_db = pickle.load(pickle_in)\n",
    "        print(\"here\")\n",
    "    else:\n",
    "        #file does not exists\n",
    "        # make a file and load it\n",
    "        user_db = {}\n",
    "    return user_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a user to the data base\n",
    "def add_new_user(user_db):\n",
    "    # taking name as input \n",
    "    name = input('enter the name of the user \\n')\n",
    "    #initializing the haar cascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    \n",
    "    counter  = 0\n",
    "    while(True):\n",
    "        ret,img= cap.read()\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "        cv2.imshow('face',img)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_gray = resize_img(roi_gray)\n",
    "            cv2.imwrite('images/user.'+str(name) +'.jpg',roi_gray)\n",
    "            counter = counter +1\n",
    "        cv2.imshow('face',img)\n",
    "        cv2.waitKey(500)\n",
    "        counter = counter + 1\n",
    "        if counter >10:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    #extracting the features from the image\n",
    "    encoding = img_to_encoding(\"images/user.\" + str(name)+'.jpg', FRmodel)\n",
    "    user_db[name] = encoding\n",
    "    print(encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_db = init_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the name of the user \n",
      "aditya\n",
      "[[-0.03067915 -0.03308417  0.06261619  0.01209736 -0.19272609 -0.02302803\n",
      "  -0.10248576  0.04268445 -0.0452455   0.06091624 -0.06352763  0.02978161\n",
      "   0.07109603  0.01422419  0.15368867 -0.08024036 -0.12662938 -0.03018125\n",
      "  -0.00166848  0.02473959  0.12780455  0.08748152 -0.00444623  0.03721877\n",
      "   0.00645332 -0.00031399  0.07297224  0.06748682  0.07038001 -0.08335285\n",
      "   0.06980877  0.15430519  0.03985602 -0.13620143 -0.04433297  0.05421957\n",
      "  -0.01495051 -0.0903709  -0.07927143  0.03415517  0.0647811  -0.07733681\n",
      "  -0.03100774 -0.04119853  0.00355659  0.07667991  0.01110022  0.27865338\n",
      "  -0.02085057 -0.07877432  0.05897596  0.00206359 -0.00686322  0.07142898\n",
      "  -0.02029522 -0.10963446  0.01536063  0.05838886  0.08384919 -0.06870884\n",
      "  -0.03189722  0.03290441  0.22035412  0.15682928  0.17512913  0.08645524\n",
      "  -0.17069393 -0.03826286 -0.01290048  0.0465887   0.10998306  0.02144232\n",
      "   0.0437413  -0.15144433 -0.1092502   0.06271245 -0.26307052 -0.03587886\n",
      "  -0.05669141  0.02352823  0.08236647  0.10764228 -0.02678797 -0.05815159\n",
      "   0.06811845 -0.08264234  0.07642808  0.08047848 -0.06462464  0.0039777\n",
      "  -0.0272635  -0.0969445  -0.10496993 -0.1571143  -0.0242468  -0.07714805\n",
      "   0.04040436  0.18919207 -0.1037083   0.15300469  0.03359785  0.05427676\n",
      "   0.17706399 -0.15898593 -0.1079809   0.0096094   0.15284413  0.06573745\n",
      "  -0.09549037 -0.05438659  0.02685638 -0.00745782 -0.05026265  0.02856868\n",
      "  -0.02411707  0.05451318 -0.01885455 -0.02762626 -0.06537144 -0.05805259\n",
      "  -0.03494896 -0.08472589 -0.02898705 -0.10517849 -0.05884225  0.13418414\n",
      "   0.0689451   0.02214074]]\n"
     ]
    }
   ],
   "source": [
    "add_new_user(user_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
